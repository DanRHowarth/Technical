{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical: Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as bkend\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Flatten, convolutional, pooling\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.client import device_lib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "\n",
    "* Text:\n",
    "    * Write out high-level intuition for AE (wiki)\n",
    "    * Develop questions for later study (widki) \n",
    "    * Introduce each type of autoencoder\n",
    "    * Utilise notes, Blog, DLwP, Hamad and Ajit's notes\n",
    "    * Read DL book chapter (read through, don't take endless notes)\n",
    "    * Write about what you discover in the code\n",
    "    * Relate to GANs\n",
    "• Code:\n",
    "    * Vanilla, Denoising, Convolutional, Variational\n",
    "    * Use MNIST and insurance; perhaps RR data set\n",
    "    * Understand outputs of encoders and decoders \n",
    "    * Code in the models using variables; experiment with layers and other structures \n",
    "    * Code as a class, start with deconstructing and understanding Hamaad's\n",
    "* Go through Chp 6 Deep Learning with Python notebook - loads of interesting stuff in there\n",
    "* Understand whcih lessons to transfer to Adam:\n",
    "    * generators\n",
    "    * RNN/LSTM for time series \n",
    "    * autoencoders\n",
    "\n",
    "## Outcomes \n",
    "\n",
    "• Understand autoencoders, PCA, GANs and how they relate to each other\n",
    "• Understand the code required to implement them\n",
    "• Apply to data and understand the benefit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "**Meterology Datasets**\n",
    "\n",
    "• Meterology dataset used in RNN: https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.3-advanced-usage-of-recurrent-neural-networks.ipynb\n",
    "\n",
    "• https://github.com/hamaadshah/hackathon_june_2018/blob/master/hackathon.ipynb\n",
    "\n",
    "• https://github.com/hamaadshah/autoencoders/blob/master/Python/autoencoders.ipynb\n",
    "\n",
    "**Representational Learning**\n",
    "\n",
    "• https://github.com/hamaadshah/autoencoders_public/tree/master/Python\n",
    "\n",
    "• https://blog.keras.io/building-autoencoders-in-keras.html \n",
    "\n",
    "**Bayesian Inference**\n",
    "\n",
    "• https://towardsdatascience.com/automatic-feature-engineering-using-deep-learning-and-bayesian-inference-application-to-computer-7b2bb8dc7351\\\n",
    "\n",
    "**GANs**\n",
    "\n",
    "• https://github.com/hamaadshah/gan_public\n",
    "\n",
    "• https://medium.com/@Moscow25/gans-will-change-the-world-7ed6ae8515ca\n",
    "\n",
    "• https://towardsdatascience.com/automatic-feature-engineering-using-generative-adversarial-networks-8e24b3c16bf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Autoencoders\n",
    "\n",
    "* Let's get out terminology right...we *encode* a representation of the data and then decode it to get back to a form of the data.\n",
    "* You can pass the enoded data on to any ML algo. You can build an autoencoder and include it as part of your pipeline\n",
    "* Why encode then decode? What is the difference between the encoded data and the normal input data?\n",
    "    * DL Book: simply creating a copy of x tells us little. Setting the parameters such that the encodng creates a representation of the features in less dimensionsis more useful.\n",
    "    * But why choose to decode once we have encoded a representation of the data?\n",
    "* What ways of doing it are there? How many methods? With what impact? \n",
    "* What are all the different types?\n",
    "    * Vanilla\n",
    "    * Denoising\n",
    "    * 1D Convolution, 2D \n",
    "    * Seq2Seq\n",
    "* How autoencoders coded/structured? What governs the choice of layers? what governs the activation functions, normalization etc? Is it similar to other DL models (i.e. some knowledge, some intuition?) How do you know they are successful? What is their objective function? What differs for different types of autoencoders? What does this mean for their success or otherwise?\n",
    "* How do autoencoders compare with other methods of feature engineering/dimensionality reduction? Is it right to think of them in the same family, and if not why not?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "* Attempts to automatically learn good features or representations \n",
    "* Autoencoders for automatic feature engineering. The idea is to automatically learn a set of features from raw data that can be useful in supervised learning tasks such as in computer vision and insurance.\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meterology data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0e797d07d03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m                      batch_size=1000)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mpipe_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m pipe_base = pipe_base.fit(X=np.reshape(train_gen[0], [train_gen[0].shape[0], train_gen[0].shape[1] * \n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd()\n",
    "fname = os.path.join(data_dir, \"jena_climate_2009_2016.csv\")\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "# check to see if this could have been taken care of with open - `the \\n param\n",
    "lines = data.split(\"\\n\")\n",
    "header = lines[0].split(\",\")\n",
    "lines = lines[1:]\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]]\n",
    "    float_data[i, :] = values\n",
    "\n",
    "mean = float_data[:20000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:20000].std(axis=0)\n",
    "float_data /= std    \n",
    "    \n",
    "def generator(data,\n",
    "              lookback,\n",
    "              delay,\n",
    "              min_index,\n",
    "              max_index,\n",
    "              shuffle=False,\n",
    "              batch_size=25,\n",
    "              step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    \n",
    "    i = min_index + lookback\n",
    "  \n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "      \n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "    \n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "\n",
    "        return samples, targets\n",
    "\n",
    "lookback = 360 # We use 60 hours for our training window: 360 * 10 / 60 = 60 hours.\n",
    "step = 6 # Each row represents hourly measurements: 6 * 10 / 60 = 1 hour.\n",
    "delay = 144 # We predict the temperature 1 day ahead: 144 * 10 / 60 = 24 hours.\n",
    "\n",
    "train_gen = generator(data=float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step,\n",
    "                      batch_size=1000)\n",
    "\n",
    "test_gen = generator(data=float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     shuffle=False,\n",
    "                     step=step,\n",
    "                     batch_size=1000)\n",
    "\n",
    "pipe_base = Pipeline(steps=[(\"model\", RandomForestRegressor())])\n",
    "\n",
    "pipe_base = pipe_base.fit(X=np.reshape(train_gen[0], [train_gen[0].shape[0], train_gen[0].shape[1] * \n",
    "                                                      train_gen[0].shape[2]]), y=train_gen[1])\n",
    "\n",
    "print(\"The MSE score for the meteorology regression task without autoencoders: %.6f.\" \n",
    "      % sklearn.metrics.mean_squared_error(y_pred=pipe_base.predict(X=np.reshape(test_gen[0], \n",
    "        [test_gen[0].shape[0], test_gen[0].shape[1] * test_gen[0].shape[2]])), y_true=test_gen[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Autoencoder\n",
    "• class autoencoder developed by Hamad\n",
    "• code an autoencoder as a function and then move on to other autoencoders. Provide top level description and play with parameters. look at DLWP, Blog, and Guerillion \n",
    "• loop back to code the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoders_keras.vanilla_autoencoder import VanillaAutoencoder \n",
    "\n",
    "autoencoder = VanillaAutoencoder(n_feat=train_gen[0].shape[1] * train_gen[0].shape[2],\n",
    "                                 n_epoch=50,\n",
    "                                 batch_size=25,\n",
    "                                 encoder_layers=5,\n",
    "                                 decoder_layers=8,\n",
    "                                 n_hidden_units=100,\n",
    "                                 encoding_dim=50,\n",
    "                                 denoising=None)\n",
    "\n",
    "print(autoencoder.autoencoder.summary())\n",
    "\n",
    "pipe_autoencoder = Pipeline(steps=[(\"autoencoder\", autoencoder),\n",
    "                                   (\"scaler\", StandardScaler()),\n",
    "                                   (\"model\", RandomForestRegressor())])\n",
    "\n",
    "pipe_autoencoder = pipe_autoencoder.fit(X=np.reshape(train_gen[0], [train_gen[0].shape[0], \n",
    "                                        train_gen[0].shape[1] * train_gen[0].shape[2]]),y=train_gen[1])\n",
    "    \n",
    "print(\"The MSE score for the meteorology regression task with an autoencoder: %.6f.\" \n",
    "      % sklearn.metrics.mean_squared_error(y_pred=pipe_autoencoder.predict(X=np.reshape(test_gen[0], \n",
    "        [test_gen[0].shape[0], test_gen[0].shape[1] * test_gen[0].shape[2]])), y_true=test_gen[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions from running the model above:**\n",
    "* How does the fit function work aceoss the pipeline? what is the shape we fit in?\n",
    "    * think we need to flatten the input (28,60,14 and feed that in)\n",
    "* How does the autoencoder train? looks like through epochs, like other models\n",
    "* What does vanilla mean?\n",
    "* Remind yourself of batch normalization and dense layers (think this is just feed forward)\n",
    "* We do we use a standard scaler and a feature sclae in the first part of the code?\n",
    "* How is the autoencoder output fed in to the regression model? (might require a look at the class as well as the code above)\n",
    "* How have the parameters been used to represent the data in another dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding a vanilla autoencoder\n",
    "* start off by using the Keras blog code - this is a different dataset. \n",
    "* type up, understand each line and then apply to the weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# we need to specify the size of our encoded data, as a variable\n",
    "encoding_dim = 32  # assuming 784 as the input_dim, this is a compression factor of 24.5\n",
    "\n",
    "# input dimension placholder    \n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# encoded is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim,activation='relu')(input_img)\n",
    "\n",
    "# decoded is the lossy reconstruction of the input\n",
    "decoded = Dense(784,activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps the an input to its reconstruction\n",
    "# the Model class seems to match input to output generally\n",
    "autoencoder = Model(input_img,decoded)\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# learning: Dense creates a tensor (a certain sort). Model turns them into a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breaking down the characteristics of the model a little more...**\n",
    "* we will see that we have created tensors of certain lengths\n",
    "* these only become a model with the Model function\n",
    "* I would suggest Input is a container of some sort, used to pass in the values to the other stages of the model\n",
    "* encoded is a tensor too, but with more functionality (an activation function), as is decoded\n",
    "* what is interesting is that it doesn't become a model until the Model layer, which takes only the original input_img (once the model is fit, this will be the pixel values), and the decoded layer\n",
    "* so our encoded representation of the input is 'simply' the input tensor reduced in dimensions using a *relu* activation function - i.e it looks like there is no encoder Model here - *so how is this different than just a normal feedforward model?* \n",
    "    * of course, the model is trained on itself.\n",
    "    * but the model will have layers of params, each representing part of the overall representation of the model, how do we know which is the deconstruction (encoded) and reconstruction (decoded) layer?\n",
    "        * I believe this will be based on the number of parameters - we know 32<784 and that the output layer is 784, so 32 has to be a deconstruction of 784, and 784 a reconstruction. \n",
    "        * Presumably, through gradient descent, we update the parameters in the layers to be as close as possible to the original input (you could see the coefficients mirroring in a two layer model? *check understanding of the layers*\n",
    "        * So what is our encoded layer in multi-layer models, do we get to decided that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is input_image?\n",
    "#input_img.dtype\n",
    "input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Relu:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is encoded?\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x11aa86cc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model does indeed call up some specific code \n",
    "autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a separate encoder model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "=================================================================\n",
      "Total params: 25,120\n",
      "Trainable params: 25,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we also create a separate encoder model\n",
    "# note that this includes encoded as the output layer, part of the autoencoder model\n",
    "# after the autoencoder has been trained, we can use the param values on just the encoder\n",
    "# by passing in encoder\n",
    "encoder = Model(input_img,encoded)\n",
    "# I believe that this compresses data only, and doesn't train it back to x\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x11fcfe908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: why do we use Model here and not just the encoded layer from above? Would that not have our representation at the end of training? \n",
    "* I wonder if it is because you can't train just a tensor? or that you can't extract the params from just a tensor\n",
    "* Also, how will this model create the same params as the model with a decoder layer, as we are not modelling against the output (input), we are modelling against the compressed tensors?\n",
    "    * It might be that, because we pass in *encoded*, if we run the full model first, we will get those values in our model as well.\n",
    "    * But, again, why run this model at all, if all we need is the params at the encoder stage? what is about it being a Model that is important\n",
    "        * Model allows you fit, compile, and have other attributes\n",
    "* the code here refers to the functional Model API, which does pass one layer to the next using the () at the end of the line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets create a separate decoder model**\n",
    "* Looks like the main thing that matters is the input and output dimensions, we aren't modelling anything yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also create a separate decoder model ## what does Model() enable us to do?  \n",
    "\n",
    "# create a placholder for the encoded input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model (which was the decoded layer)\n",
    "# note that the syntax here does not include the (previous_layer) thing, which makes me thing that is passed on \n",
    "# as part of retrieving the layers - or is taken care of by passing the input into the Model(output()) bit\n",
    "decoder_layer = autencoder.layers[-1]\n",
    "# create the decoded model\n",
    "decoder = Model(encoded_input,decoder_layer(encoded_input))\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to compile the model - described in the blog as 'configure' \n",
    "\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now import the dataset, remembering that we do not need the y labels\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train,_),(x_test,_) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we normalise the values of the test and training set and flatten the 28x28 images into 784\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "x_train = x_train.reshape((len(x_train),np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape(len(x_test),np.prod(x_train.shape[1:]))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now can fit and train the autoencoder\n",
    "autoencoder.fit(x_train,x_train,\n",
    "               epochs=50,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions/Comments:**\n",
    "* It looks like our basic autoencoder is just a model that compresses data to an arbitrary specified dimension\n",
    "    * Is it as easy as simply specifying the dims we want?\n",
    "    * Do we have to have in mind that the compressed dims are then trained back to the input data?\n",
    "    * If so, how do we account for this in the above if we want to pull off the encoded values - i.e. make sure we don't pull off the compressed dims that have just been compressed\n",
    "* When instantiating and developing our models, why do we need dim placeholders?\n",
    "    * *because this is just a model, it needs be compiled and mapped to the dataset, so the dims need to match the anticipated dataset. Looks like Model requires the dimensions to be established upfront*\n",
    "    \n",
    "**Actions**\n",
    "* Need to pass back in to a DL/Keras intro how Model, Input and Dense work, their arguments, etc. \n",
    "    * Looks like Model has fit, compile and predict methods attached to it\n",
    "    * Why relu and sigmoid? What else works (sessions on different activation functions)\n",
    "    * Why did we choose the optimizers and loss function that we did? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
